{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab3da82e-1bd5-4980-90b8-225714aeea40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\nachi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nachi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "from collections import Counter\n",
    "from langdetect import detect, DetectorFactory\n",
    "from googletrans import Translator\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# Setup\n",
    "DetectorFactory.seed = 0\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Load JSON\n",
    "with open('amazon_search_results_1.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42c884cf-f7ec-423a-8f45-90ff4b064cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Language Distribution:\n",
      "it: 159\n",
      "es: 258\n",
      "en: 1869\n",
      "so: 35\n",
      "et: 5\n",
      "ro: 29\n",
      "de: 132\n",
      "tl: 2\n",
      "ca: 11\n",
      "af: 26\n",
      "fr: 105\n",
      "hr: 2\n",
      "id: 6\n",
      "no: 11\n",
      "ar: 62\n",
      "ja: 13\n",
      "pl: 4\n",
      "sv: 3\n",
      "tr: 30\n",
      "da: 11\n",
      "nl: 11\n",
      "pt: 18\n",
      "fa: 2\n",
      "fi: 4\n",
      "undetermined: 7\n",
      "vi: 2\n",
      "cs: 4\n",
      "sk: 2\n",
      "sl: 2\n",
      "cy: 5\n",
      "sq: 1\n",
      "ko: 1\n",
      "hu: 1\n"
     ]
    }
   ],
   "source": [
    "# Detect language\n",
    "raw_reviews = []\n",
    "language_counts = Counter()\n",
    "for product in data:\n",
    "    product_name = product.get(\"text\", \"Unknown Product\")\n",
    "    if \"Reviewer Details\" in product:\n",
    "        for review in product[\"Reviewer Details\"].values():\n",
    "            review_text = review.get(\"review\", \"\")\n",
    "            try:\n",
    "                lang = detect(review_text)\n",
    "            except:\n",
    "                lang = \"undetermined\"\n",
    "            language_counts[lang] += 1\n",
    "            raw_reviews.append({\n",
    "                \"product\": product_name,\n",
    "                \"original_review\": review_text,\n",
    "                \"language\": lang\n",
    "            })\n",
    "\n",
    "# Translate non-English reviews\n",
    "translator = Translator()\n",
    "for r in raw_reviews:\n",
    "    if r[\"language\"] != \"en\":\n",
    "        try:\n",
    "            r[\"translated_review\"] = translator.translate(r[\"original_review\"], dest='en').text\n",
    "        except:\n",
    "            r[\"translated_review\"] = r[\"original_review\"]\n",
    "    else:\n",
    "        r[\"translated_review\"] = r[\"original_review\"]\n",
    "\n",
    "print(\"\\n Language Distribution:\")\n",
    "for lang, count in language_counts.items():\n",
    "    print(f\"{lang}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd0a738-ae43-42b0-95c4-3e2ea8934b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def clean_text(text):\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)     \n",
    "\n",
    "    # Remove HTML entities\n",
    "    text = re.sub(r\"&[a-z]+;\", \"\", text)\n",
    "\n",
    "    # Normalize unicode to ASCII\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8')\n",
    "\n",
    "    # Remove numbers\n",
    "    text = re.sub(r\"\\d+\", \"\", text)\n",
    "\n",
    "    # Normalize whitespace\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be160b96-952e-4cd0-a56f-4bf6254f1e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean all reviews\n",
    "for r in raw_reviews:\n",
    "    r[\"cleaned_review\"] = clean_text(r[\"translated_review\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03a576a3-db97-42b3-92e6-bda34ce48bfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Top 50 Most Frequent Words:\n",
      "skin: 2840\n",
      "product: 1074\n",
      "face: 965\n",
      "use: 783\n",
      "cleanser: 735\n",
      "good: 694\n",
      "dry: 516\n",
      "using: 512\n",
      "clean: 452\n",
      "like: 438\n",
      "really: 402\n",
      "well: 397\n",
      "sensitive: 391\n",
      "wash: 373\n",
      "love: 360\n",
      "great: 350\n",
      "oil: 308\n",
      "without: 305\n",
      "soft: 303\n",
      "gentle: 302\n",
      "leaves: 289\n",
      "feeling: 288\n",
      "used: 282\n",
      "one: 282\n",
      "recommend: 281\n",
      "also: 280\n",
      "acne: 280\n",
      "products: 255\n",
      "feel: 251\n",
      "time: 250\n",
      "feels: 245\n",
      "oily: 238\n",
      "makeup: 216\n",
      "cleansing: 214\n",
      "little: 209\n",
      "much: 204\n",
      "cleaning: 189\n",
      "foam: 189\n",
      "first: 187\n",
      "works: 185\n",
      "best: 185\n",
      "make: 182\n",
      "smell: 175\n",
      "nice: 171\n",
      "would: 168\n",
      "gel: 162\n",
      "price: 155\n",
      "cleaner: 155\n",
      "long: 154\n",
      "lot: 154\n"
     ]
    }
   ],
   "source": [
    "# Top 50 frequent words\n",
    "stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "words = []\n",
    "for r in raw_reviews:\n",
    "    tokens = re.findall(r'\\b\\w+\\b', r[\"cleaned_review\"].lower())\n",
    "    tokens = [word for word in tokens if word not in stopwords]\n",
    "    words.extend(tokens)\n",
    "top_50_words = Counter(words).most_common(50)\n",
    "\n",
    "print(\"\\n Top 50 Most Frequent Words:\")\n",
    "for word, freq in top_50_words:\n",
    "    print(f\"{word}: {freq}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50c8ee8b-45ac-4a99-a3aa-11299ffeb508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Total Reviews Processed: 2833\n",
      "\n",
      " VADER Sentiment Output saved as 'vader_sentiment_output.json'\n"
     ]
    }
   ],
   "source": [
    "# VADER sentiment analysis\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "sentiment_results = []\n",
    "for r in raw_reviews:\n",
    "    score = sid.polarity_scores(r[\"cleaned_review\"])\n",
    "    sentiment = \"Positive\" if score[\"compound\"] >= 0.05 else \"Negative\" if score[\"compound\"] <= -0.05 else \"Neutral\"\n",
    "    sentiment_results.append({\n",
    "        \"product\": r[\"product\"],\n",
    "        \"review\": r[\"cleaned_review\"],\n",
    "        \"vader_score\": score,\n",
    "        \"vader_sentiment\": sentiment\n",
    "    })\n",
    "\n",
    "print(f\"\\n Total Reviews Processed: {len(raw_reviews)}\")\n",
    "\n",
    "# Save sentiment results\n",
    "with open('vader_sentiment_output.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(sentiment_results, f, indent=4)\n",
    "\n",
    "print(\"\\n VADER Sentiment Output saved as 'vader_sentiment_output.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7b397b71-a1e7-4a2e-a5ee-0cc6aeab0696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Product level average  VADER sentiment scores by taking average of all reviews associated with the product\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # Initialize storage for product-wise sentiment aggregation\n",
    "# product_scores = defaultdict(lambda: {\n",
    "#     \"count\": 0,\n",
    "#     \"neg\": 0.0,\n",
    "#     \"neu\": 0.0,\n",
    "#     \"pos\": 0.0,\n",
    "#     \"compound\": 0.0\n",
    "# })\n",
    "\n",
    "# # Aggregate VADER scores per product\n",
    "# for entry in sentiment_results:\n",
    "#     product = entry[\"product\"]\n",
    "#     score = entry[\"vader_score\"]\n",
    "\n",
    "#     product_scores[product][\"count\"] += 1\n",
    "#     product_scores[product][\"neg\"] += score[\"neg\"]\n",
    "#     product_scores[product][\"neu\"] += score[\"neu\"]\n",
    "#     product_scores[product][\"pos\"] += score[\"pos\"]\n",
    "#     product_scores[product][\"compound\"] += score[\"compound\"]\n",
    "\n",
    "# # Compute average scores\n",
    "# aggregated_scores = []\n",
    "# for product, values in product_scores.items():\n",
    "#     count = values[\"count\"]\n",
    "#     avg_compound = round(values[\"compound\"] / count, 4)\n",
    "\n",
    "#     if avg_compound >= 0.05:\n",
    "#         overall_sentiment = \"Positive\"\n",
    "#     elif avg_compound <= -0.05:\n",
    "#         overall_sentiment = \"Negative\"\n",
    "#     else:\n",
    "#         overall_sentiment = \"Neutral\"\n",
    "\n",
    "#     avg_score = {\n",
    "#         \"product\": product,\n",
    "#         \"avg_neg\": round(values[\"neg\"] / count, 4),\n",
    "#         \"avg_neu\": round(values[\"neu\"] / count, 4),\n",
    "#         \"avg_pos\": round(values[\"pos\"] / count, 4),\n",
    "#         \"avg_compound\": avg_compound,\n",
    "#         \"review_count\": count,\n",
    "#         \"overall_sentiment\": overall_sentiment\n",
    "#     }\n",
    "\n",
    "#     aggregated_scores.append(avg_score)\n",
    "\n",
    "# print(f\"\\n Total Number of Unique Products: {len(aggregated_scores)}\")\n",
    "\n",
    "# # Print summary and save to file\n",
    "# print(\"\\n Product-Level Average VADER Sentiment Scores:\")\n",
    "# for item in aggregated_scores:\n",
    "#     print(json.dumps(item, indent=4))\n",
    "\n",
    "# with open('product_vader_averages.json', 'w', encoding='utf-8') as f:\n",
    "#     json.dump(aggregated_scores, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "260a3760-02af-4b2b-ac64-9b56bd8ff60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize aggregation structure\n",
    "product_scores = defaultdict(lambda: {\n",
    "    \"count\": 0,\n",
    "    \"neg\": 0.0,\n",
    "    \"neu\": 0.0,\n",
    "    \"pos\": 0.0,\n",
    "    \"compound\": 0.0,\n",
    "    \"positive_reviews\": 0,\n",
    "    \"negative_reviews\": 0,\n",
    "    \"neutral_reviews\": 0\n",
    "})\n",
    "\n",
    "# Aggregate scores and sentiment counts\n",
    "for entry in sentiment_results:\n",
    "    product = entry[\"product\"]\n",
    "    score = entry[\"vader_score\"]\n",
    "    sentiment = entry[\"vader_sentiment\"]\n",
    "\n",
    "    product_scores[product][\"count\"] += 1\n",
    "    product_scores[product][\"neg\"] += score[\"neg\"]\n",
    "    product_scores[product][\"neu\"] += score[\"neu\"]\n",
    "    product_scores[product][\"pos\"] += score[\"pos\"]\n",
    "    product_scores[product][\"compound\"] += score[\"compound\"]\n",
    "\n",
    "    if sentiment == \"Positive\":\n",
    "        product_scores[product][\"positive_reviews\"] += 1\n",
    "    elif sentiment == \"Negative\":\n",
    "        product_scores[product][\"negative_reviews\"] += 1\n",
    "    else:\n",
    "        product_scores[product][\"neutral_reviews\"] += 1\n",
    "\n",
    "# Compute averages and prepare output\n",
    "aggregated_scores = []\n",
    "for product, values in product_scores.items():\n",
    "    count = values[\"count\"]\n",
    "    avg_compound = round(values[\"compound\"] / count, 4)\n",
    "\n",
    "    if avg_compound >= 0.05:\n",
    "        overall_sentiment = \"Positive\"\n",
    "    elif avg_compound <= -0.05:\n",
    "        overall_sentiment = \"Negative\"\n",
    "    else:\n",
    "        overall_sentiment = \"Neutral\"\n",
    "\n",
    "    avg_score = {\n",
    "        \"product\": product,\n",
    "        \"avg_neg\": round(values[\"neg\"] / count, 4),\n",
    "        \"avg_neu\": round(values[\"neu\"] / count, 4),\n",
    "        \"avg_pos\": round(values[\"pos\"] / count, 4),\n",
    "        \"avg_compound\": avg_compound,\n",
    "        \"review_count\": count,\n",
    "        \"positive_reviews\": values[\"positive_reviews\"],\n",
    "        \"negative_reviews\": values[\"negative_reviews\"],\n",
    "        \"neutral_reviews\": values[\"neutral_reviews\"],\n",
    "        \"overall_sentiment\": overall_sentiment\n",
    "    }\n",
    "\n",
    "    aggregated_scores.append(avg_score)\n",
    "\n",
    "# Save the scores to CSV file\n",
    "df = pd.DataFrame(aggregated_scores)\n",
    "df.to_csv(\"product_vader_scores.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf572ef-33ac-417b-b700-371650d512ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
